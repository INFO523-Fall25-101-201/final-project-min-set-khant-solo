[
  {
    "objectID": "proposal.html",
    "href": "proposal.html",
    "title": "INFO-523-DATA MININIG_Final Project ‘BMW Car Price Analysis & Prediction’",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns"
  },
  {
    "objectID": "proposal.html#dataset",
    "href": "proposal.html#dataset",
    "title": "INFO-523-DATA MININIG_Final Project ‘BMW Car Price Analysis & Prediction’",
    "section": "Dataset",
    "text": "Dataset\n\ndata = pd.read_csv(\"data/bmw_worldwide_sales.csv\")\ndata.head(10)\n\n\n\n\n\n\n\n\nModel\nYear\nRegion\nColor\nFuel_Type\nTransmission\nEngine_Size_L\nMileage_KM\nPrice_USD\nSales_Volume\nSales_Classification\n\n\n\n\n0\n5 Series\n2016\nAsia\nRed\nPetrol\nManual\n3.5\n151748\n98740\n8300\nHigh\n\n\n1\ni8\n2013\nNorth America\nRed\nHybrid\nAutomatic\n1.6\n121671\n79219\n3428\nLow\n\n\n2\n5 Series\n2022\nNorth America\nBlue\nPetrol\nAutomatic\n4.5\n10991\n113265\n6994\nLow\n\n\n3\nX3\n2024\nMiddle East\nBlue\nPetrol\nAutomatic\n1.7\n27255\n60971\n4047\nLow\n\n\n4\n7 Series\n2020\nSouth America\nBlack\nDiesel\nManual\n2.1\n122131\n49898\n3080\nLow\n\n\n5\n5 Series\n2017\nMiddle East\nSilver\nDiesel\nManual\n1.9\n171362\n42926\n1232\nLow\n\n\n6\ni8\n2022\nEurope\nWhite\nDiesel\nManual\n1.8\n196741\n55064\n7949\nHigh\n\n\n7\nM5\n2014\nAsia\nBlack\nDiesel\nAutomatic\n1.6\n121156\n102778\n632\nLow\n\n\n8\nX3\n2016\nSouth America\nWhite\nDiesel\nAutomatic\n1.7\n48073\n116482\n8944\nHigh\n\n\n9\ni8\n2019\nEurope\nWhite\nElectric\nManual\n3.0\n35700\n96257\n4411\nLow"
  },
  {
    "objectID": "proposal.html#dataset-overview",
    "href": "proposal.html#dataset-overview",
    "title": "INFO-523-DATA MININIG_Final Project ‘BMW Car Price Analysis & Prediction’",
    "section": "Dataset Overview",
    "text": "Dataset Overview\n\ndata.describe()\ndata.shape\n\n(50000, 11)\n\n\nThis dataset — BMW Worldwide Sales Records (2010–2024) — contains over 50,000 records of BMW’s sales and specifications across multiple regions. Key features include: Model, Year, Engine_Size_L, Transmission, Fuel_Type, Color, Region, Price, and Sales_Volume. This dataset was chosen because it provides a diverse range of attributes for exploring market behavior, pricing trends, and customer preferences in the automotive industry."
  },
  {
    "objectID": "proposal.html#questions",
    "href": "proposal.html#questions",
    "title": "INFO-523-DATA MININIG_Final Project ‘BMW Car Price Analysis & Prediction’",
    "section": "Questions",
    "text": "Questions\n\nWhat are the key factors influencing BMW used-car prices in the market?\nCan machine learning models accurately predict used-car prices?\nHow stable are these predictions over time?\nUsing a temporal split, how well can the model predict pricing trends for “next year”?"
  },
  {
    "objectID": "proposal.html#analysis-plan",
    "href": "proposal.html#analysis-plan",
    "title": "INFO-523-DATA MININIG_Final Project ‘BMW Car Price Analysis & Prediction’",
    "section": "Analysis Plan",
    "text": "Analysis Plan\n\nData Cleaning & Preparation\n\nHandle missing values\nStandardize numerical units\nEncode categorical variables\nEnsure time-related variables are aligned for temporal analysis\n\nExploratory Data Analysis (EDA)\n\nPrice trends by year, region, and model\nCorrelation analysis between price and vehicle attributes\nIdentify patterns that may indicate shifting market preferences\n\nModeling Approach\n\nApply Machine Learning Models:\nLinear Regression\nDecision Tree Regression\nRandom Forest Regression\nEvaluate using:\nRMSE, MAE, R²\nPerform:\nFeature importance analysis\nTemporal train–test split to simulate predicting next-year price trends\n\nVisualization Dashboard\n\nBuild clear, interactive visualizations using matplotlib / seaborn\nInclude:\nPrice distribution\nTrend lines across years\nModel performance summary\nModeling :\n\nApply regression techniques (e.g., Linear or Decision Tree Regression) to predict car price based on selected features.\n\nVisualization Dashboard:\n\nBuild clear, interactive plots for trends and insights using matplotlib and seaborn.\n\nEthical AI Use Disclosure:\n\nAI tools (e.g., ChatGPT) were used ethically for code debugging, idea exploration, and documentation enhancement.\nAll datasets are real and sourced from Kaggle."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This project was developed by [Team Name] For INFO 523 - Data Mining and Discovery at the University of Arizona, taught by Dr. Greg Chism. The team is comprised of the following team members.\n\nTeam member 1: One sentence description of Team member 1 (e.g., year, major, etc.).\nTeam member 2: One sentence description of Team member 2 (e.g., year, major, etc.).\nTeam member 3: One sentence description of Team member 3 (e.g., year, major, etc.).\nTeam member 4: One sentence description of Team member 4 (e.g., year, major, etc.)."
  },
  {
    "objectID": "presentation.html",
    "href": "presentation.html",
    "title": "Project title",
    "section": "",
    "text": "The presentation is created using the Quarto CLI\n## sets the start of a new slide\n\n\n\n\nYou can use plain text\n\n\n\nor bullet points1\n\n\nor in two columns\n\n\n\nlike\nthis\n\n\n\n\n\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                    mpg   R-squared:                       0.073\nModel:                            OLS   Adj. R-squared:                  0.070\nMethod:                 Least Squares   F-statistic:                     30.59\nDate:                Wed, 29 Oct 2025   Prob (F-statistic):           5.84e-08\nTime:                        16:38:54   Log-Likelihood:                -1346.4\nNo. Observations:                 392   AIC:                             2697.\nDf Residuals:                     390   BIC:                             2705.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         35.8015      2.266     15.800      0.000      31.347      40.257\nspeed       -354.7055     64.129     -5.531      0.000    -480.788    -228.623\n==============================================================================\nOmnibus:                       27.687   Durbin-Watson:                   0.589\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               18.976\nSkew:                           0.420   Prob(JB):                     7.57e-05\nKurtosis:                       2.323   Cond. No.                         169.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSome text\ngoes here"
  },
  {
    "objectID": "presentation.html#quarto",
    "href": "presentation.html#quarto",
    "title": "Project title",
    "section": "",
    "text": "The presentation is created using the Quarto CLI\n## sets the start of a new slide"
  },
  {
    "objectID": "presentation.html#layouts",
    "href": "presentation.html#layouts",
    "title": "Project title",
    "section": "",
    "text": "You can use plain text\n\n\n\nor bullet points1\n\n\nor in two columns\n\n\n\nlike\nthis"
  },
  {
    "objectID": "presentation.html#code",
    "href": "presentation.html#code",
    "title": "Project title",
    "section": "",
    "text": "OLS Regression Results                            \n==============================================================================\nDep. Variable:                    mpg   R-squared:                       0.073\nModel:                            OLS   Adj. R-squared:                  0.070\nMethod:                 Least Squares   F-statistic:                     30.59\nDate:                Wed, 29 Oct 2025   Prob (F-statistic):           5.84e-08\nTime:                        16:38:54   Log-Likelihood:                -1346.4\nNo. Observations:                 392   AIC:                             2697.\nDf Residuals:                     390   BIC:                             2705.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         35.8015      2.266     15.800      0.000      31.347      40.257\nspeed       -354.7055     64.129     -5.531      0.000    -480.788    -228.623\n==============================================================================\nOmnibus:                       27.687   Durbin-Watson:                   0.589\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               18.976\nSkew:                           0.420   Prob(JB):                     7.57e-05\nKurtosis:                       2.323   Cond. No.                         169.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
  },
  {
    "objectID": "presentation.html#plot-and-text",
    "href": "presentation.html#plot-and-text",
    "title": "Project title",
    "section": "",
    "text": "Some text\ngoes here"
  },
  {
    "objectID": "presentation.html#tables",
    "href": "presentation.html#tables",
    "title": "Project title",
    "section": "Tables",
    "text": "Tables\nIf you want to generate a table, make sure it is in the HTML format (instead of Markdown or other formats), e.g.,\n\n\n\n\n\n\n\n\n\n\n\n\nspecies\n\n\n\nisland\n\n\n\nbill_length_mm\n\n\n\nbill_depth_mm\n\n\n\nflipper_length_mm\n\n\n\nbody_mass_g\n\n\n\nsex\n\n\n\n\n\n\n\n\n\n\n\n0\n\n\n\nAdelie\n\n\n\nTorgersen\n\n\n\n39.1\n\n\n\n18.7\n\n\n\n181.0\n\n\n\n3750.0\n\n\n\nMale\n\n\n\n\n\n\n\n1\n\n\n\nAdelie\n\n\n\nTorgersen\n\n\n\n39.5\n\n\n\n17.4\n\n\n\n186.0\n\n\n\n3800.0\n\n\n\nFemale\n\n\n\n\n\n\n\n2\n\n\n\nAdelie\n\n\n\nTorgersen\n\n\n\n40.3\n\n\n\n18.0\n\n\n\n195.0\n\n\n\n3250.0\n\n\n\nFemale\n\n\n\n\n\n\n\n4\n\n\n\nAdelie\n\n\n\nTorgersen\n\n\n\n36.7\n\n\n\n19.3\n\n\n\n193.0\n\n\n\n3450.0\n\n\n\nFemale\n\n\n\n\n\n\n\n5\n\n\n\nAdelie\n\n\n\nTorgersen\n\n\n\n39.3\n\n\n\n20.6\n\n\n\n190.0\n\n\n\n3650.0\n\n\n\nMale"
  },
  {
    "objectID": "presentation.html#images",
    "href": "presentation.html#images",
    "title": "Project title",
    "section": "Images",
    "text": "Images\n\n\n\nImage credit: Danielle Navarro, Percolate."
  },
  {
    "objectID": "presentation.html#math-expressions",
    "href": "presentation.html#math-expressions",
    "title": "Project title",
    "section": "Math Expressions",
    "text": "Math Expressions\nYou can write LaTeX math expressions inside a pair of dollar signs, e.g. $\\alpha+\\beta$ renders \\(\\alpha + \\beta\\). You can use the display style with double dollar signs:\n$$\\bar{X}=\\frac{1}{n}\\sum_{i=1}^nX_i$$\n\\[\n\\bar{X}=\\frac{1}{n}\\sum_{i=1}^nX_i\n\\]\nLimitations:\n\nThe source code of a LaTeX math expression must be in one line, unless it is inside a pair of double dollar signs, in which case the starting $$ must appear in the very beginning of a line, followed immediately by a non-space character, and the ending $$ must be at the end of a line, led by a non-space character;\nThere should not be spaces after the opening $ or before the closing $."
  },
  {
    "objectID": "presentation.html#feeling-adventurous",
    "href": "presentation.html#feeling-adventurous",
    "title": "Project title",
    "section": "Feeling adventurous?",
    "text": "Feeling adventurous?\n\nYou are welcomed to use the default styling of the slides. In fact, that’s what I expect majority of you will do. You will differentiate yourself with the content of your presentation.\nBut some of you might want to play around with slide styling. Some solutions for this can be found at https://quarto.org/docs/presentations/revealjs."
  },
  {
    "objectID": "presentation.html#footnotes",
    "href": "presentation.html#footnotes",
    "title": "Project title",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAnd add footnotes↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Project Title",
    "section": "",
    "text": "Add project abstract here."
  },
  {
    "objectID": "index.html#abstract",
    "href": "index.html#abstract",
    "title": "Project Title",
    "section": "",
    "text": "Add project abstract here."
  },
  {
    "objectID": "all_notebook/01_data_preparation.html",
    "href": "all_notebook/01_data_preparation.html",
    "title": "BMW Car Sales Data Preparation & Cleaning",
    "section": "",
    "text": "# Import Required Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Set display options\npd.set_option('display.max_columns', None)\nsns.set(style=\"whitegrid\")\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\n\n\n# Load the Dataset\n# Load the dataset from the parent folder's data directory\ndf= pd.read_csv(\"../data/bmw_worldwide_sales.csv\")\n# quick snapshot\nprint(\"shape:\", df.shape)\ndisplay(df.head(10))\ndisplay(df.info())\ndisplay(df.describe(include='all').T)\n\nshape: (50000, 11)\n\n\n\n\n\n\n\n\n\nModel\nYear\nRegion\nColor\nFuel_Type\nTransmission\nEngine_Size_L\nMileage_KM\nPrice_USD\nSales_Volume\nSales_Classification\n\n\n\n\n0\n5 Series\n2016\nAsia\nRed\nPetrol\nManual\n3.5\n151748\n98740\n8300\nHigh\n\n\n1\ni8\n2013\nNorth America\nRed\nHybrid\nAutomatic\n1.6\n121671\n79219\n3428\nLow\n\n\n2\n5 Series\n2022\nNorth America\nBlue\nPetrol\nAutomatic\n4.5\n10991\n113265\n6994\nLow\n\n\n3\nX3\n2024\nMiddle East\nBlue\nPetrol\nAutomatic\n1.7\n27255\n60971\n4047\nLow\n\n\n4\n7 Series\n2020\nSouth America\nBlack\nDiesel\nManual\n2.1\n122131\n49898\n3080\nLow\n\n\n5\n5 Series\n2017\nMiddle East\nSilver\nDiesel\nManual\n1.9\n171362\n42926\n1232\nLow\n\n\n6\ni8\n2022\nEurope\nWhite\nDiesel\nManual\n1.8\n196741\n55064\n7949\nHigh\n\n\n7\nM5\n2014\nAsia\nBlack\nDiesel\nAutomatic\n1.6\n121156\n102778\n632\nLow\n\n\n8\nX3\n2016\nSouth America\nWhite\nDiesel\nAutomatic\n1.7\n48073\n116482\n8944\nHigh\n\n\n9\ni8\n2019\nEurope\nWhite\nElectric\nManual\n3.0\n35700\n96257\n4411\nLow\n\n\n\n\n\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50000 entries, 0 to 49999\nData columns (total 11 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   Model                 50000 non-null  object \n 1   Year                  50000 non-null  int64  \n 2   Region                50000 non-null  object \n 3   Color                 50000 non-null  object \n 4   Fuel_Type             50000 non-null  object \n 5   Transmission          50000 non-null  object \n 6   Engine_Size_L         50000 non-null  float64\n 7   Mileage_KM            50000 non-null  int64  \n 8   Price_USD             50000 non-null  int64  \n 9   Sales_Volume          50000 non-null  int64  \n 10  Sales_Classification  50000 non-null  object \ndtypes: float64(1), int64(4), object(6)\nmemory usage: 4.2+ MB\n\n\nNone\n\n\n\n\n\n\n\n\n\ncount\nunique\ntop\nfreq\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nModel\n50000\n11\n7 Series\n4666\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nYear\n50000.0\nNaN\nNaN\nNaN\n2017.0157\n4.324459\n2010.0\n2013.0\n2017.0\n2021.0\n2024.0\n\n\nRegion\n50000\n6\nAsia\n8454\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nColor\n50000\n6\nRed\n8463\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nFuel_Type\n50000\n4\nHybrid\n12716\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nTransmission\n50000\n2\nManual\n25154\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nEngine_Size_L\n50000.0\nNaN\nNaN\nNaN\n3.24718\n1.009078\n1.5\n2.4\n3.2\n4.1\n5.0\n\n\nMileage_KM\n50000.0\nNaN\nNaN\nNaN\n100307.20314\n57941.509344\n3.0\n50178.0\n100388.5\n150630.25\n199996.0\n\n\nPrice_USD\n50000.0\nNaN\nNaN\nNaN\n75034.6009\n25998.248882\n30000.0\n52434.75\n75011.5\n97628.25\n119998.0\n\n\nSales_Volume\n50000.0\nNaN\nNaN\nNaN\n5067.51468\n2856.767125\n100.0\n2588.0\n5087.0\n7537.25\n9999.0\n\n\nSales_Classification\n50000\n2\nLow\n34754\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\n\n\n# Copy original for safety\ndf_raw = df.copy()\n\n# Normalize column names\ndf.columns = [c.strip() for c in df.columns]\n\n# Standardzing string columns\nstr_cols = ['Model', 'Region', 'Color', 'Fuel_Type', 'Transmission', 'Sales_Classification']\nfor c in str_cols:\n    df[c] = df[c].astype(str).str.strip().replace({'nan': np.nan})\n    df[c] = df[c].str.title() \n\n\n#  Fix Year and numeric types\ndf['Year'] = pd.to_numeric(df['Year'], errors='coerce')\nnum_cols = ['Engine_Size_L','Mileage_KM','Price_USD','Sales_Volume']\nfor c in num_cols:\n    df[c] = pd.to_numeric(df[c], errors='coerce')\n\n\n# Add Derived Feature — Car Age\nCURRENT_YEAR = 2025\ndf['Car_Age'] = CURRENT_YEAR - df['Year']\n\n\n# Transmission normalization\ndf['Transmission'] = df['Transmission'].replace({\n    'Auto': 'Automatic',\n    'Man': 'Manual',\n    'Automated Manual': 'Automatic'\n})\n\n\n# If fuel is present as one-hot, consolidate:\nif set(['Fuel_Type_Petrol','Fuel_Type_Hybrid','Fuel_Type_Electric']).issubset(df.columns):\n    df['Fuel_Type'] = np.select(\n        [df['Fuel_Type_Petrol'] == True, df['Fuel_Type_Hybrid'] == True, df['Fuel_Type_Electric'] == True],\n        ['Petrol','Hybrid','Electric'],\n        default=np.nan\n    )\n    df['Fuel_Type'] = df['Fuel_Type'].fillna('Other')\n\n\n# Create log Price feature for modeling\ndf['Log_Price_USD'] = np.log1p(df['Price_USD'])\n\n\n# Missing Value and duplicate Handling\ndups = df.duplicated().sum()\nprint(\"duplicates:\", dups)\nif dups&gt;0:\n    df = df.drop_duplicates()\n\nduplicates: 0\n\n\n\n# imputation:\ndf['Engine_Size_L'] = df.groupby('Model')['Engine_Size_L'].transform(lambda x: x.fillna(x.median()))\ndf['Engine_Size_L'] = df['Engine_Size_L'].fillna(df['Engine_Size_L'].median())\n# Drop rows missing the target Price_USD\ndf = df[~df['Price_USD'].isna()].copy()\n# After cleaning\nprint(\"shape after cleaning:\", df.shape)\nprint(df.isna().sum())\n\nshape after cleaning: (50000, 13)\nModel                   0\nYear                    0\nRegion                  0\nColor                   0\nFuel_Type               0\nTransmission            0\nEngine_Size_L           0\nMileage_KM              0\nPrice_USD               0\nSales_Volume            0\nSales_Classification    0\nCar_Age                 0\nLog_Price_USD           0\ndtype: int64\n\n\n\n\n\n\nfrom scipy import stats\n# Flag extreme price outliers using IQR:\ndef flag_outliers_iqr(series, k=1.5):\n    q1, q3 = series.quantile([0.25,0.75])\n    iqr = q3 - q1\n    lower, upper = q1 - k*iqr, q3 + k*iqr\n    return (series &lt; lower) | (series &gt; upper), lower, upper\n\nfor col in ['Price_USD','Mileage_KM','Engine_Size_L','Sales_Volume']:\n    mask, low, up = flag_outliers_iqr(df[col].dropna())\n    pct = mask.mean()*100\n    print(f\"{col}: outlier pct ~ {pct:.2f}%, lower={low:.2f}, upper={up:.2f}\")\n\n# Option: keep but cap at 1st/99th percentiles\nfor col in ['Price_USD','Mileage_KM','Sales_Volume']:\n    lower, upper = df[col].quantile(0.01), df[col].quantile(0.99)\n    df[col] = df[col].clip(lower, upper)\n\nPrice_USD: outlier pct ~ 0.00%, lower=-15355.50, upper=165418.50\nMileage_KM: outlier pct ~ 0.00%, lower=-100500.38, upper=301308.62\nEngine_Size_L: outlier pct ~ 0.00%, lower=-0.15, upper=6.65\nSales_Volume: outlier pct ~ 0.00%, lower=-4835.88, upper=14961.12\n\n\n\n\n\n\n# Create the feautures \n# Price per KM\ndf['Price_per_KM'] = df['Price_USD'] / (df['Mileage_KM'].replace(0, np.nan))\ndf['Price_per_KM'] = df['Price_per_KM'].fillna(df['Price_per_KM'].median())\n\n\n# Engine size buckets\ndf['Engine_Bin'] = pd.cut(df['Engine_Size_L'], bins=[0,1.6,2.0,3.0,4.0,10],\n                          labels=['&lt;=1.6','1.7-2.0','2.1-3.0','3.1-4.0','&gt;4.0'])\n\n# Age bucket\ndf['Age_Bin'] = pd.cut(df['Car_Age'], bins=[-1,1,3,6,10,30], labels=['0-1','2-3','4-6','7-10','10+'])\n\n# Model popularity (sales per model)\nmodel_sales = df.groupby('Model')['Sales_Volume'].sum().reset_index().rename(columns={'Sales_Volume':'Total_Sales_Model'})\ndf = df.merge(model_sales, on='Model', how='left')\n\n\n\n\n\n# Price Distribution\nplt.figure(figsize=(10, 6))\nsns.histplot(\n    df['Price_USD'],\n    bins=40,\n    kde=True,\n    color='#1f77b4',  \n    edgecolor='black',\n    alpha=0.7\n)\nplt.title(\"Price Distribution (USD)\", fontsize=16, pad=15)\nplt.xlabel(\"Price (USD)\", fontsize=12)\nplt.ylabel(\"Count\", fontsize=12)\nplt.tight_layout()\nplt.show()\n\n# Log Price Distribution \nplt.figure(figsize=(10, 6))\nsns.histplot(\n    df['log_Price_USD'],\n    bins=40,\n    kde=True,\n    color='#7f7f7f',   \n    edgecolor='black',\n    alpha=0.7\n)\nplt.title(\"Log Price Distribution\", fontsize=16, pad=15)\nplt.xlabel(\"Log(Price USD)\", fontsize=12)\nplt.ylabel(\"Count\", fontsize=12)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Price by Fuel Type (boxplot)\nplt.figure(figsize=(10, 6))\nsns.boxplot(\n    data=df,\n    x='Fuel_Type',\n    y='Price_USD',\n    palette=['#1f77b4', '#7f7f7f', '#d62728'], \n    fliersize=5,   \n    linewidth=1.2\n)\nplt.title(\"Price Distribution by Fuel Type\", fontsize=16, pad=15)\nplt.xlabel(\"Fuel Type\", fontsize=12)\nplt.ylabel(\"Price (USD)\", fontsize=12)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Engine Size vs Price (bubble chart) \nplt.figure(figsize=(10, 6))\nsns.scatterplot(\n    data=df,\n    x='Engine_Size_L',\n    y='Price_USD',\n    hue='Region',\n    size='Sales_Volume',\n    sizes=(50, 600),\n    alpha=0.75,\n    edgecolor='black',\n    linewidth=0.8,\n    palette='Set2'  \n)\nplt.title(\"Engine Size vs Price by Region (Bubble = Sales Volume)\", fontsize=16, pad=15)\nplt.xlabel(\"Engine Size (Liters)\", fontsize=12)\nplt.ylabel(\"Price (USD)\", fontsize=12)\nplt.legend(\n    title=\"Region / Sales Volume\",\n    bbox_to_anchor=(1.05, 1),\n    loc='upper left',\n    frameon=False\n)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Top-selling models by region \nregion_model_sales = (\n    df.groupby(['Region', 'Model'])['Sales_Volume']\n      .sum()\n      .reset_index()\n)\n# Pick the top-selling model in each region\ntop_per_region = region_model_sales.loc[\n    region_model_sales.groupby('Region')['Sales_Volume'].idxmax()\n]\n# Plot\nplt.figure(figsize=(10, 5))\nsns.barplot(\n    data=top_per_region,\n    x='Region',\n    y='Sales_Volume',\n    hue='Model',\n    dodge=False,\n    palette=['#003366', '#1f77b4', '#7f8c8d', '#d62728', '#c0c0c0']  \n)\nplt.title(\"Top-Selling BMW Model per Region\", fontsize=16, pad=15)\nplt.xlabel(\"Region\", fontsize=12)\nplt.ylabel(\"Sales Volume\", fontsize=12)\nplt.legend(title=\"Model\", bbox_to_anchor=(1.05, 1), loc='upper left', frameon=False)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Sales by Color and Region\n# Create the pivot table\npivot_color = (\n    df.groupby(['Region', 'Color'])['Sales_Volume']\n      .sum()\n      .unstack()\n      .fillna(0)\n)\n# Plot\npivot_color.plot(\n    kind='bar',\n    stacked=True,\n    figsize=(12, 6),\n    color=['#000000', '#1f77b4', '#7f7f7f', '#d62728', '#c0c0c0', '#ffffff'],\n    edgecolor='black'\n)\n\nplt.title(\"Sales by Color and Region\", fontsize=16, pad=15)\nplt.ylabel(\"Sales Volume\", fontsize=12)\nplt.xlabel(\"Region\", fontsize=12)\nplt.legend(title=\"Color\", bbox_to_anchor=(1.05, 1), loc='upper left', frameon=False)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Price Relationships by Feature\n# Categorical features for boxplots \ncat_features = ['Model', 'Fuel_Type', 'Transmission', 'Region']\n\nplt.figure(figsize=(16, 12))\nsns.set_style(\"whitegrid\")\npalette = sns.color_palette(\"Set2\")  \n\nfor i, col in enumerate(cat_features, 1):\n    plt.subplot(2, 2, i)\n    sns.boxplot(\n        x=col,\n        y='Price_USD',\n        data=df,\n        palette=palette,\n        fliersize=5,\n        linewidth=1.2\n    )\n    plt.xticks(rotation=45, ha='right', fontsize=10)\n    plt.yticks(fontsize=10)\n    plt.title(f'Price Distribution by {col}', fontsize=14, pad=10)\n    plt.ylabel(\"Price (USD)\", fontsize=12)\n    plt.xlabel(col, fontsize=12)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Top 10 Models by Sales Volume \ntop_models = df.groupby('Model')['Sales_Volume'].sum().sort_values(ascending=False).head(10)\n\nplt.figure(figsize=(10, 6))\nsns.set_style(\"whitegrid\")\npalette = sns.color_palette(\"Blues_d\", n_colors=10)  \n\nbarplot = sns.barplot(\n    x=top_models.values,\n    y=top_models.index,\n    palette=palette\n)\nfor i, v in enumerate(top_models.values):\n    barplot.text(v + max(top_models.values)*0.01, i, f\"{v:,}\", color='black', va='center', fontsize=10)\n\nplt.title(\"Top 10 BMW Models by Global Sales Volume\", fontsize=16, pad=15)\nplt.xlabel(\"Total Sales Volume\", fontsize=12)\nplt.ylabel(\"Model\", fontsize=12)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n# Average Price Trend by Year \nyearly_avg = df.groupby('Year')['Price_USD'].mean().reset_index()\n\nplt.figure(figsize=(10, 6))\nsns.set_style(\"whitegrid\")\nsns.lineplot(\n    x='Year',\n    y='Price_USD',\n    data=yearly_avg,\n    marker='o',\n    color='#003366', \n    linewidth=2.0\n)\n\nplt.title(\"BMW Price Trends (2010–2024)\", fontsize=16, pad=15)\nplt.xlabel(\"Year\", fontsize=12)\nplt.ylabel(\"Average Price (USD)\", fontsize=12)\nplt.xticks(rotation=0)\nplt.yticks(fontsize=10)\nplt.grid(True, linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Correlation Heatmap   \n# Numeric columns for correlation \nnum_cols = ['Engine_Size_L', 'Mileage_KM', 'Price_USD', 'Sales_Volume', 'Car_Age', 'Price_per_KM']\n\n# Plot correlation heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    df[num_cols].corr(),\n    annot=True,\n    fmt=\".2f\",\n    cmap='coolwarm',  \n    linewidths=0.8,\n    linecolor='white',\n    cbar_kws={\"shrink\": 0.8}\n)\nplt.title(\"Correlation Matrix (Numeric Features)\", fontsize=16, pad=15)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Pairplot for Key Numerical Features \n# Key numerical features \nnum_features = ['Price_USD', 'Mileage_KM', 'Engine_Size_L', 'Car_Age']\n\n# Pairplot\nsns.set(style=\"whitegrid\", font_scale=1.1)\npairplot_fig = sns.pairplot(\n    df[num_features],\n    diag_kind='kde',\n    plot_kws={'alpha':0.6, 's':40, 'edgecolor':'k'},\n    diag_kws={'shade':True, 'alpha':0.6}\n)\n\npairplot_fig.fig.suptitle(\"Pairwise Relationships of Key Numerical Features\", fontsize=16, y=1.02)\npairplot_fig.fig.set_size_inches(12, 10)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Select numeric features for PCA/Modeling\nfeatures = ['Engine_Size_L','Mileage_KM','Sales_Volume','Car_Age']\nX_num = df[features].fillna(0)\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_num)\n\npca = PCA(n_components=3)\npca_res = pca.fit_transform(X_scaled)\nprint(\"Explained variance ratios:\", pca.explained_variance_ratio_)\n\n# Random Forest feature importance for Price (log target)\nX_model = df[features + ['Total_Sales_Model']]  \ny = df['log_Price_USD'].fillna(df['log_Price_USD'].median())\n\nrf = RandomForestRegressor(n_estimators=200, random_state=42)\nrf.fit(X_model.fillna(0), y)\nimportances = pd.Series(rf.feature_importances_, index=X_model.columns).sort_values(ascending=False)\nprint(importances)\n\nExplained variance ratios: [0.25301259 0.25026363 0.24907334]\nMileage_KM           0.308223\nSales_Volume         0.302352\nEngine_Size_L        0.167998\nCar_Age              0.122695\nTotal_Sales_Model    0.098732\ndtype: float64\n\n\n\n\n\n\nimport os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\ndf_model = df.copy()\n# Categorical columns to encode \ncat_cols = ['Region', 'Model', 'Fuel_Type', 'Transmission', 'Color']\n# Convert categorical variables to dummies\ndf_model = pd.get_dummies(df_model, columns=cat_cols, drop_first=True)\n# Create log-transformed columns safely\nfor col in ['Price_USD', 'Sales_Volume']:\n    new_col = 'log_' + col\n    df_model[new_col] = df_model[col].apply(lambda x: np.log(x) if pd.notnull(x) and x &gt; 0 else 0)\n\n# Ensure all columns are numeric (no categories)\nfor col in df_model.columns:\n    if df_model[col].dtype.name == 'category':\n        df_model[col] = df_model[col].astype(str)\n\n# Select features for modeling\nfeature_cols = [c for c in df_model.columns if c not in ['Price_USD', 'log_Price_USD']]\n\n# Keep only numeric columns for scaling\nX = df_model[feature_cols].select_dtypes(include='number').fillna(0)\n\n# Standardize numeric features \nscaler = StandardScaler()\nX_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n\n# Target variable \ny = df_model['log_Price_USD']\n\n# Combine scaled features with target \ndf_ready = pd.concat([X_scaled, y.reset_index(drop=True)], axis=1)\n\n# Save CSV in existing data\nos.makedirs(\"data\", exist_ok=True)\noutput_path = \"data/bmw_modeling_ready_scaled.csv\"\ndf_ready.to_csv(output_path, index=False)"
  },
  {
    "objectID": "all_notebook/01_data_preparation.html#cleaning-standardization-of-bmw-car-sales-dataset-for-analysis-and-modeling.",
    "href": "all_notebook/01_data_preparation.html#cleaning-standardization-of-bmw-car-sales-dataset-for-analysis-and-modeling.",
    "title": "BMW Car Sales Data Preparation & Cleaning",
    "section": "",
    "text": "# Copy original for safety\ndf_raw = df.copy()\n\n# Normalize column names\ndf.columns = [c.strip() for c in df.columns]\n\n# Standardzing string columns\nstr_cols = ['Model', 'Region', 'Color', 'Fuel_Type', 'Transmission', 'Sales_Classification']\nfor c in str_cols:\n    df[c] = df[c].astype(str).str.strip().replace({'nan': np.nan})\n    df[c] = df[c].str.title() \n\n\n#  Fix Year and numeric types\ndf['Year'] = pd.to_numeric(df['Year'], errors='coerce')\nnum_cols = ['Engine_Size_L','Mileage_KM','Price_USD','Sales_Volume']\nfor c in num_cols:\n    df[c] = pd.to_numeric(df[c], errors='coerce')\n\n\n# Add Derived Feature — Car Age\nCURRENT_YEAR = 2025\ndf['Car_Age'] = CURRENT_YEAR - df['Year']\n\n\n# Transmission normalization\ndf['Transmission'] = df['Transmission'].replace({\n    'Auto': 'Automatic',\n    'Man': 'Manual',\n    'Automated Manual': 'Automatic'\n})\n\n\n# If fuel is present as one-hot, consolidate:\nif set(['Fuel_Type_Petrol','Fuel_Type_Hybrid','Fuel_Type_Electric']).issubset(df.columns):\n    df['Fuel_Type'] = np.select(\n        [df['Fuel_Type_Petrol'] == True, df['Fuel_Type_Hybrid'] == True, df['Fuel_Type_Electric'] == True],\n        ['Petrol','Hybrid','Electric'],\n        default=np.nan\n    )\n    df['Fuel_Type'] = df['Fuel_Type'].fillna('Other')\n\n\n# Create log Price feature for modeling\ndf['Log_Price_USD'] = np.log1p(df['Price_USD'])\n\n\n# Missing Value and duplicate Handling\ndups = df.duplicated().sum()\nprint(\"duplicates:\", dups)\nif dups&gt;0:\n    df = df.drop_duplicates()\n\nduplicates: 0\n\n\n\n# imputation:\ndf['Engine_Size_L'] = df.groupby('Model')['Engine_Size_L'].transform(lambda x: x.fillna(x.median()))\ndf['Engine_Size_L'] = df['Engine_Size_L'].fillna(df['Engine_Size_L'].median())\n# Drop rows missing the target Price_USD\ndf = df[~df['Price_USD'].isna()].copy()\n# After cleaning\nprint(\"shape after cleaning:\", df.shape)\nprint(df.isna().sum())\n\nshape after cleaning: (50000, 13)\nModel                   0\nYear                    0\nRegion                  0\nColor                   0\nFuel_Type               0\nTransmission            0\nEngine_Size_L           0\nMileage_KM              0\nPrice_USD               0\nSales_Volume            0\nSales_Classification    0\nCar_Age                 0\nLog_Price_USD           0\ndtype: int64"
  },
  {
    "objectID": "all_notebook/01_data_preparation.html#outlier-detection-handling",
    "href": "all_notebook/01_data_preparation.html#outlier-detection-handling",
    "title": "BMW Car Sales Data Preparation & Cleaning",
    "section": "",
    "text": "from scipy import stats\n# Flag extreme price outliers using IQR:\ndef flag_outliers_iqr(series, k=1.5):\n    q1, q3 = series.quantile([0.25,0.75])\n    iqr = q3 - q1\n    lower, upper = q1 - k*iqr, q3 + k*iqr\n    return (series &lt; lower) | (series &gt; upper), lower, upper\n\nfor col in ['Price_USD','Mileage_KM','Engine_Size_L','Sales_Volume']:\n    mask, low, up = flag_outliers_iqr(df[col].dropna())\n    pct = mask.mean()*100\n    print(f\"{col}: outlier pct ~ {pct:.2f}%, lower={low:.2f}, upper={up:.2f}\")\n\n# Option: keep but cap at 1st/99th percentiles\nfor col in ['Price_USD','Mileage_KM','Sales_Volume']:\n    lower, upper = df[col].quantile(0.01), df[col].quantile(0.99)\n    df[col] = df[col].clip(lower, upper)\n\nPrice_USD: outlier pct ~ 0.00%, lower=-15355.50, upper=165418.50\nMileage_KM: outlier pct ~ 0.00%, lower=-100500.38, upper=301308.62\nEngine_Size_L: outlier pct ~ 0.00%, lower=-0.15, upper=6.65\nSales_Volume: outlier pct ~ 0.00%, lower=-4835.88, upper=14961.12"
  },
  {
    "objectID": "all_notebook/01_data_preparation.html#feature-engineering-useful-features",
    "href": "all_notebook/01_data_preparation.html#feature-engineering-useful-features",
    "title": "BMW Car Sales Data Preparation & Cleaning",
    "section": "",
    "text": "# Create the feautures \n# Price per KM\ndf['Price_per_KM'] = df['Price_USD'] / (df['Mileage_KM'].replace(0, np.nan))\ndf['Price_per_KM'] = df['Price_per_KM'].fillna(df['Price_per_KM'].median())\n\n\n# Engine size buckets\ndf['Engine_Bin'] = pd.cut(df['Engine_Size_L'], bins=[0,1.6,2.0,3.0,4.0,10],\n                          labels=['&lt;=1.6','1.7-2.0','2.1-3.0','3.1-4.0','&gt;4.0'])\n\n# Age bucket\ndf['Age_Bin'] = pd.cut(df['Car_Age'], bins=[-1,1,3,6,10,30], labels=['0-1','2-3','4-6','7-10','10+'])\n\n# Model popularity (sales per model)\nmodel_sales = df.groupby('Model')['Sales_Volume'].sum().reset_index().rename(columns={'Sales_Volume':'Total_Sales_Model'})\ndf = df.merge(model_sales, on='Model', how='left')"
  },
  {
    "objectID": "all_notebook/01_data_preparation.html#exploratory-visualizations",
    "href": "all_notebook/01_data_preparation.html#exploratory-visualizations",
    "title": "BMW Car Sales Data Preparation & Cleaning",
    "section": "",
    "text": "# Price Distribution\nplt.figure(figsize=(10, 6))\nsns.histplot(\n    df['Price_USD'],\n    bins=40,\n    kde=True,\n    color='#1f77b4',  \n    edgecolor='black',\n    alpha=0.7\n)\nplt.title(\"Price Distribution (USD)\", fontsize=16, pad=15)\nplt.xlabel(\"Price (USD)\", fontsize=12)\nplt.ylabel(\"Count\", fontsize=12)\nplt.tight_layout()\nplt.show()\n\n# Log Price Distribution \nplt.figure(figsize=(10, 6))\nsns.histplot(\n    df['log_Price_USD'],\n    bins=40,\n    kde=True,\n    color='#7f7f7f',   \n    edgecolor='black',\n    alpha=0.7\n)\nplt.title(\"Log Price Distribution\", fontsize=16, pad=15)\nplt.xlabel(\"Log(Price USD)\", fontsize=12)\nplt.ylabel(\"Count\", fontsize=12)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Price by Fuel Type (boxplot)\nplt.figure(figsize=(10, 6))\nsns.boxplot(\n    data=df,\n    x='Fuel_Type',\n    y='Price_USD',\n    palette=['#1f77b4', '#7f7f7f', '#d62728'], \n    fliersize=5,   \n    linewidth=1.2\n)\nplt.title(\"Price Distribution by Fuel Type\", fontsize=16, pad=15)\nplt.xlabel(\"Fuel Type\", fontsize=12)\nplt.ylabel(\"Price (USD)\", fontsize=12)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Engine Size vs Price (bubble chart) \nplt.figure(figsize=(10, 6))\nsns.scatterplot(\n    data=df,\n    x='Engine_Size_L',\n    y='Price_USD',\n    hue='Region',\n    size='Sales_Volume',\n    sizes=(50, 600),\n    alpha=0.75,\n    edgecolor='black',\n    linewidth=0.8,\n    palette='Set2'  \n)\nplt.title(\"Engine Size vs Price by Region (Bubble = Sales Volume)\", fontsize=16, pad=15)\nplt.xlabel(\"Engine Size (Liters)\", fontsize=12)\nplt.ylabel(\"Price (USD)\", fontsize=12)\nplt.legend(\n    title=\"Region / Sales Volume\",\n    bbox_to_anchor=(1.05, 1),\n    loc='upper left',\n    frameon=False\n)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Top-selling models by region \nregion_model_sales = (\n    df.groupby(['Region', 'Model'])['Sales_Volume']\n      .sum()\n      .reset_index()\n)\n# Pick the top-selling model in each region\ntop_per_region = region_model_sales.loc[\n    region_model_sales.groupby('Region')['Sales_Volume'].idxmax()\n]\n# Plot\nplt.figure(figsize=(10, 5))\nsns.barplot(\n    data=top_per_region,\n    x='Region',\n    y='Sales_Volume',\n    hue='Model',\n    dodge=False,\n    palette=['#003366', '#1f77b4', '#7f8c8d', '#d62728', '#c0c0c0']  \n)\nplt.title(\"Top-Selling BMW Model per Region\", fontsize=16, pad=15)\nplt.xlabel(\"Region\", fontsize=12)\nplt.ylabel(\"Sales Volume\", fontsize=12)\nplt.legend(title=\"Model\", bbox_to_anchor=(1.05, 1), loc='upper left', frameon=False)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Sales by Color and Region\n# Create the pivot table\npivot_color = (\n    df.groupby(['Region', 'Color'])['Sales_Volume']\n      .sum()\n      .unstack()\n      .fillna(0)\n)\n# Plot\npivot_color.plot(\n    kind='bar',\n    stacked=True,\n    figsize=(12, 6),\n    color=['#000000', '#1f77b4', '#7f7f7f', '#d62728', '#c0c0c0', '#ffffff'],\n    edgecolor='black'\n)\n\nplt.title(\"Sales by Color and Region\", fontsize=16, pad=15)\nplt.ylabel(\"Sales Volume\", fontsize=12)\nplt.xlabel(\"Region\", fontsize=12)\nplt.legend(title=\"Color\", bbox_to_anchor=(1.05, 1), loc='upper left', frameon=False)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Price Relationships by Feature\n# Categorical features for boxplots \ncat_features = ['Model', 'Fuel_Type', 'Transmission', 'Region']\n\nplt.figure(figsize=(16, 12))\nsns.set_style(\"whitegrid\")\npalette = sns.color_palette(\"Set2\")  \n\nfor i, col in enumerate(cat_features, 1):\n    plt.subplot(2, 2, i)\n    sns.boxplot(\n        x=col,\n        y='Price_USD',\n        data=df,\n        palette=palette,\n        fliersize=5,\n        linewidth=1.2\n    )\n    plt.xticks(rotation=45, ha='right', fontsize=10)\n    plt.yticks(fontsize=10)\n    plt.title(f'Price Distribution by {col}', fontsize=14, pad=10)\n    plt.ylabel(\"Price (USD)\", fontsize=12)\n    plt.xlabel(col, fontsize=12)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Top 10 Models by Sales Volume \ntop_models = df.groupby('Model')['Sales_Volume'].sum().sort_values(ascending=False).head(10)\n\nplt.figure(figsize=(10, 6))\nsns.set_style(\"whitegrid\")\npalette = sns.color_palette(\"Blues_d\", n_colors=10)  \n\nbarplot = sns.barplot(\n    x=top_models.values,\n    y=top_models.index,\n    palette=palette\n)\nfor i, v in enumerate(top_models.values):\n    barplot.text(v + max(top_models.values)*0.01, i, f\"{v:,}\", color='black', va='center', fontsize=10)\n\nplt.title(\"Top 10 BMW Models by Global Sales Volume\", fontsize=16, pad=15)\nplt.xlabel(\"Total Sales Volume\", fontsize=12)\nplt.ylabel(\"Model\", fontsize=12)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n# Average Price Trend by Year \nyearly_avg = df.groupby('Year')['Price_USD'].mean().reset_index()\n\nplt.figure(figsize=(10, 6))\nsns.set_style(\"whitegrid\")\nsns.lineplot(\n    x='Year',\n    y='Price_USD',\n    data=yearly_avg,\n    marker='o',\n    color='#003366', \n    linewidth=2.0\n)\n\nplt.title(\"BMW Price Trends (2010–2024)\", fontsize=16, pad=15)\nplt.xlabel(\"Year\", fontsize=12)\nplt.ylabel(\"Average Price (USD)\", fontsize=12)\nplt.xticks(rotation=0)\nplt.yticks(fontsize=10)\nplt.grid(True, linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Correlation Heatmap   \n# Numeric columns for correlation \nnum_cols = ['Engine_Size_L', 'Mileage_KM', 'Price_USD', 'Sales_Volume', 'Car_Age', 'Price_per_KM']\n\n# Plot correlation heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    df[num_cols].corr(),\n    annot=True,\n    fmt=\".2f\",\n    cmap='coolwarm',  \n    linewidths=0.8,\n    linecolor='white',\n    cbar_kws={\"shrink\": 0.8}\n)\nplt.title(\"Correlation Matrix (Numeric Features)\", fontsize=16, pad=15)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Pairplot for Key Numerical Features \n# Key numerical features \nnum_features = ['Price_USD', 'Mileage_KM', 'Engine_Size_L', 'Car_Age']\n\n# Pairplot\nsns.set(style=\"whitegrid\", font_scale=1.1)\npairplot_fig = sns.pairplot(\n    df[num_features],\n    diag_kind='kde',\n    plot_kws={'alpha':0.6, 's':40, 'edgecolor':'k'},\n    diag_kws={'shade':True, 'alpha':0.6}\n)\n\npairplot_fig.fig.suptitle(\"Pairwise Relationships of Key Numerical Features\", fontsize=16, y=1.02)\npairplot_fig.fig.set_size_inches(12, 10)\nplt.show()"
  },
  {
    "objectID": "all_notebook/01_data_preparation.html#pca-feature-importance",
    "href": "all_notebook/01_data_preparation.html#pca-feature-importance",
    "title": "BMW Car Sales Data Preparation & Cleaning",
    "section": "",
    "text": "from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Select numeric features for PCA/Modeling\nfeatures = ['Engine_Size_L','Mileage_KM','Sales_Volume','Car_Age']\nX_num = df[features].fillna(0)\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_num)\n\npca = PCA(n_components=3)\npca_res = pca.fit_transform(X_scaled)\nprint(\"Explained variance ratios:\", pca.explained_variance_ratio_)\n\n# Random Forest feature importance for Price (log target)\nX_model = df[features + ['Total_Sales_Model']]  \ny = df['log_Price_USD'].fillna(df['log_Price_USD'].median())\n\nrf = RandomForestRegressor(n_estimators=200, random_state=42)\nrf.fit(X_model.fillna(0), y)\nimportances = pd.Series(rf.feature_importances_, index=X_model.columns).sort_values(ascending=False)\nprint(importances)\n\nExplained variance ratios: [0.25301259 0.25026363 0.24907334]\nMileage_KM           0.308223\nSales_Volume         0.302352\nEngine_Size_L        0.167998\nCar_Age              0.122695\nTotal_Sales_Model    0.098732\ndtype: float64"
  },
  {
    "objectID": "all_notebook/01_data_preparation.html#encoding-modeling",
    "href": "all_notebook/01_data_preparation.html#encoding-modeling",
    "title": "BMW Car Sales Data Preparation & Cleaning",
    "section": "",
    "text": "import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\ndf_model = df.copy()\n# Categorical columns to encode \ncat_cols = ['Region', 'Model', 'Fuel_Type', 'Transmission', 'Color']\n# Convert categorical variables to dummies\ndf_model = pd.get_dummies(df_model, columns=cat_cols, drop_first=True)\n# Create log-transformed columns safely\nfor col in ['Price_USD', 'Sales_Volume']:\n    new_col = 'log_' + col\n    df_model[new_col] = df_model[col].apply(lambda x: np.log(x) if pd.notnull(x) and x &gt; 0 else 0)\n\n# Ensure all columns are numeric (no categories)\nfor col in df_model.columns:\n    if df_model[col].dtype.name == 'category':\n        df_model[col] = df_model[col].astype(str)\n\n# Select features for modeling\nfeature_cols = [c for c in df_model.columns if c not in ['Price_USD', 'log_Price_USD']]\n\n# Keep only numeric columns for scaling\nX = df_model[feature_cols].select_dtypes(include='number').fillna(0)\n\n# Standardize numeric features \nscaler = StandardScaler()\nX_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n\n# Target variable \ny = df_model['log_Price_USD']\n\n# Combine scaled features with target \ndf_ready = pd.concat([X_scaled, y.reset_index(drop=True)], axis=1)\n\n# Save CSV in existing data\nos.makedirs(\"data\", exist_ok=True)\noutput_path = \"data/bmw_modeling_ready_scaled.csv\"\ndf_ready.to_csv(output_path, index=False)"
  }
]